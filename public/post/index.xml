<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Victor Mandela</title>
    <link>https://victormandela.netlify.app/post/</link>
      <atom:link href="https://victormandela.netlify.app/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>&amp;copy2021</copyright><lastBuildDate>Tue, 16 Feb 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://victormandela.netlify.app/images/icon_hu22efcb094e0f25517d9b2ea60a3d74df_42984_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://victormandela.netlify.app/post/</link>
    </image>
    
    <item>
      <title>Buiding shinyApps3: Outputs</title>
      <link>https://victormandela.netlify.app/post/buiding-shinyapps3-outputs/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/buiding-shinyapps3-outputs/</guid>
      <description>&lt;h2 id=&#34;outputs-in-shinyapps&#34;&gt;OutPuts in ShinyApps&lt;/h2&gt;
&lt;p&gt;Outputs are build in shinyApps based on inputs. We use render functiond to create a variety of outputs ranging from plots &lt;strong&gt;renderPlot&lt;/strong&gt;, tables &lt;strong&gt;renderTable&lt;/strong&gt; and images &lt;strong&gt;renderImage&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;add-a-table-output&#34;&gt;Add a table output&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;In order to add any output to a Shiny app, you need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create the output (plot, table, text, etc.).&lt;/li&gt;
&lt;li&gt;Render the output object using the appropriate *render___* function.&lt;/li&gt;
&lt;li&gt;Assign the rendered object to &lt;em&gt;output$x&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Add the output to the UI using the appropriate &lt;em&gt;___Output&lt;/em&gt; function.&lt;/li&gt;
&lt;li&gt;In this example, you will add a table output to the baby names explorer app you created earlier. Don&amp;rsquo;t forget that code inside a render___ function needs to be wrapped inside curly braces (e.g. renderPlot({&amp;hellip;})).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  titlePanel(&amp;quot;What&#39;s in a Name?&amp;quot;),
  # Add select input named &amp;quot;sex&amp;quot; to choose between &amp;quot;M&amp;quot; and &amp;quot;F&amp;quot;
  selectInput(&#39;sex&#39;, &#39;Select Sex&#39;, choices = c(&amp;quot;F&amp;quot;, &amp;quot;M&amp;quot;)),
  # Add slider input named &amp;quot;year&amp;quot; to select year between 1900 and 2010
  sliderInput(&#39;year&#39;, &#39;Select Year&#39;, min = 1900, max = 2010, value = 1900),
  # CODE BELOW: Add table output named &amp;quot;table_top_10_names&amp;quot;
  tableOutput (&amp;quot;table_top_10_names&amp;quot;)
)
server &amp;lt;- function(input, output, session){
  # Function to create a data frame of top 10 names by sex and year 
  top_10_names &amp;lt;- function(){
    top_10_names &amp;lt;- babynames %&amp;gt;% 
      filter(sex == input$sex) %&amp;gt;% 
      filter(year == input$year) %&amp;gt;% 
      top_n(10, prop)
  }
  # CODE BELOW: Render a table output named &amp;quot;table_top_10_names&amp;quot;
  output$table_top_10_names &amp;lt;- renderTable ({
    top_10_names()
  })
  
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-an-interactive-table-output&#34;&gt;Add an interactive table output&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;There are multiple &lt;em&gt;htmlwidgets packages&lt;/em&gt; like DT, leaflet, plotly, etc. that provide highly interactive outputs and can be easily integrated into Shiny apps using almost the same pattern. For example, you can turn a static table in a Shiny app into an interactive table using the &lt;em&gt;DT package&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create an interactive table using DT::datatable().&lt;/li&gt;
&lt;li&gt;Render it using DT::renderDT().&lt;/li&gt;
&lt;li&gt;Display it using DT::DTOutput().&lt;/li&gt;
&lt;li&gt;In this example, you will update the app created previously, replacing the static table with an interactive table.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  titlePanel(&amp;quot;What&#39;s in a Name?&amp;quot;),
  # Add select input named &amp;quot;sex&amp;quot; to choose between &amp;quot;M&amp;quot; and &amp;quot;F&amp;quot;
  selectInput(&#39;sex&#39;, &#39;Select Sex&#39;, choices = c(&amp;quot;M&amp;quot;, &amp;quot;F&amp;quot;)),
  # Add slider input named &amp;quot;year&amp;quot; to select year between 1900 and 2010
  sliderInput(&#39;year&#39;, &#39;Select Year&#39;, min = 1900, max = 2010, value = 1900),
  # MODIFY CODE BELOW: Add a DT output named &amp;quot;table_top_10_names&amp;quot;
  DT::DTOutput(&#39;table_top_10_names&#39;)
)
server &amp;lt;- function(input, output, session){
  top_10_names &amp;lt;- function(){
    babynames %&amp;gt;% 
      filter(sex == input$sex) %&amp;gt;% 
      filter(year == input$year) %&amp;gt;% 
      top_n(10, prop)
  }
  # MODIFY CODE BELOW: Render a DT output named &amp;quot;table_top_10_names&amp;quot;
  output$table_top_10_names &amp;lt;- DT::renderDT({
    top_10_names() %&amp;gt;%
    DT::datatable()
  })
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;add-interactive-plot-output&#34;&gt;Add interactive plot output&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Similar to creating interactive tables, you can easily turn a static plot created using ggplot2 into an interactive plot using the &lt;em&gt;plotly package&lt;/em&gt;. To render an interactive plot, use plotly::renderPlotly(), and display it using plotly::plotlyOutput().&lt;/p&gt;
&lt;p&gt;Remember that just like with other render functions, the code inside plotly::renderPlotly() should be wrapped in curly braces {}!&lt;/p&gt;
&lt;p&gt;Check out the next illustrations&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  selectInput(&#39;name&#39;, &#39;Select Name&#39;, top_trendy_names$name),
  # CODE BELOW: Add a plotly output named &#39;plot_trendy_names&#39;
  plotly::plotlyOutput(&amp;quot;plot_trendy_names&amp;quot;)
)
server &amp;lt;- function(input, output, session){
  # Function to plot trends in a name
  plot_trends &amp;lt;- function(){
     babynames %&amp;gt;% 
      filter(name == input$name) %&amp;gt;% 
      ggplot(aes(x = year, y = n)) +
      geom_col()
  }
  # CODE BELOW: Render a plotly output named &#39;plot_trendy_names&#39;
output$plot_trendy_names &amp;lt;- plotly::renderPlotly({
  plot_trends()
})
  
  
}
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;benefits-of-an-interactive-plot&#34;&gt;Benefits of an interactive plot&lt;/h3&gt;
&lt;p&gt;Try interacting with the plot. You can zoom in on certain areas, zoom back out, and hover over the bars to see the values. This makes plots in your app far more interesting, and allows users to gain insights without having to see any code or data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>building shinApp4: Layouts and themes</title>
      <link>https://victormandela.netlify.app/post/building-shinapp4-layouts-and-themes/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/building-shinapp4-layouts-and-themes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Building shinyApp2: Inputs options </title>
      <link>https://victormandela.netlify.app/post/building-shinyapp2-inputs-outputs-and-layouts/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/building-shinyapp2-inputs-outputs-and-layouts/</guid>
      <description>&lt;h2 id=&#34;inputs&#34;&gt;INPUTS&lt;/h2&gt;
&lt;p&gt;Shiny provides a wide variety of inputs that allows users to provide text &lt;strong&gt;(textInput, selectInput)&lt;/strong&gt;, numbers &lt;strong&gt;(numericInput, sliderInput)&lt;/strong&gt;, booleans &lt;strong&gt;(checkBoxInput, radioInput)&lt;/strong&gt;, and dates &lt;strong&gt;(dateInput, dateRangeInput)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For example:-&lt;/p&gt;
&lt;p&gt;To select a range a name from a predifined range of choice we use - the &lt;strong&gt;selectInput&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selectInput(&amp;quot;InputID&amp;quot;,
            &amp;quot;Label&amp;quot;,
            choices = c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To choose a range of values to filter weight we can use the &lt;strong&gt;sliderInput&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sliderInput(&amp;quot;InputID&amp;quot;,
            &amp;quot;Label&amp;quot;,
            value = 1925,
            max = 2021,
            min =1900,)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To select three phones to compare from a set of 10 options we can use the &lt;strong&gt;checkBoxInput&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NoTE&lt;/strong&gt; - It&amp;rsquo;s helpful to visualize what you want your input to look like first, then choose the corresponding Shiny input. It is better to draw a &lt;strong&gt;Sketch&lt;/strong&gt; first.&lt;/p&gt;
&lt;h3 id=&#34;add-a-select-input&#34;&gt;Add a select input&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;Adding an input to a shiny app is a two step process, where you first add an &lt;strong&gt;___Input(“x”)&lt;/strong&gt; function to the UI and then access its value in the server using &lt;strong&gt;input$x&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;For example, if you want users to choose an animal from a list, you can use a selectInput, and refer to the chosen value as input$animal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selectInput(
  &#39;animal&#39;, 
  &#39;Select Animal&#39;, 
  selected = &#39;Cat&#39;, 
  choices = c(&#39;Dog&#39;, &#39;Cat&#39;)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, you will build a Shiny app that lets users visualize the top 10 most popular names by sex by adding an input to let them choose the sex.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  titlePanel(&amp;quot;What&#39;s in a Name?&amp;quot;),
  # CODE BELOW: Add select input named &amp;quot;sex&amp;quot; to choose between &amp;quot;M&amp;quot; and &amp;quot;F&amp;quot;
selectInput(&amp;quot;sex&amp;quot;, &amp;quot;What is your gender?&amp;quot;, &amp;quot;F&amp;quot;, choices = c(&amp;quot;M&amp;quot;, &amp;quot;F&amp;quot;)),
  # Add plot output to display top 10 most popular names
  plotOutput(&#39;plot_top_10_names&#39;)
)

server &amp;lt;- function(input, output, session){
  # Render plot of top 10 most popular names
  output$plot_top_10_names &amp;lt;- renderPlot({
    # Get top 10 names by sex and year
    top_10_names &amp;lt;- babynames %&amp;gt;% 
      # MODIFY CODE BELOW: Filter for the selected sex
      filter(sex == input$sex) %&amp;gt;% 
      filter(year == 1900) %&amp;gt;% 
      top_n(10, prop)
    # Plot top 10 names by sex and year
    ggplot(top_10_names, aes(x = name, y = prop)) +
      geom_col(fill = &amp;quot;#263e63&amp;quot;)
  })
}

shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;slider-input&#34;&gt;Slider Input&lt;/h3&gt;
&lt;hr&gt;
&lt;p&gt;We can add a sliderInput for year to select the range of between 1900 to 2010, with a default of 1920 by adding the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  titlePanel(&amp;quot;What&#39;s in a Name?&amp;quot;),
  # Add select input named &amp;quot;sex&amp;quot; to choose between &amp;quot;M&amp;quot; and &amp;quot;F&amp;quot;
  selectInput(&#39;sex&#39;, &#39;Select Sex&#39;, choices = c(&amp;quot;F&amp;quot;, &amp;quot;M&amp;quot;)),
  # CODE BELOW: Add slider input named &#39;year&#39; to select years  (1900 - 2010)
  sliderInput(&amp;quot;year&amp;quot;, &amp;quot;choose year&amp;quot;, value = 1900, min = 1900, max = 2010),

  # Add plot output to display top 10 most popular names
  plotOutput(&#39;plot_top_10_names&#39;)
)

server &amp;lt;- function(input, output, session){
  # Render plot of top 10 most popular names
  output$plot_top_10_names &amp;lt;- renderPlot({
    # Get top 10 names by sex and year
    top_10_names &amp;lt;- babynames %&amp;gt;% 
      filter(sex == input$sex) %&amp;gt;% 
    # MODIFY CODE BELOW: Filter for the selected year
      filter(year == input$year) %&amp;gt;% 
      top_n(10, prop)
    # Plot top 10 names by sex and year
      ggplot(top_10_names, aes(x = name, y = prop)) +
        geom_col(fill = &amp;quot;#263e63&amp;quot;)
  })
}

shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to build a ShinyApp</title>
      <link>https://victormandela.netlify.app/post/how-to-build-a-shinyapp/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/how-to-build-a-shinyapp/</guid>
      <description>&lt;h2 id=&#34;building-a-hello-world-shinyapp&#34;&gt;Building a &amp;ldquo;Hello world shinyApp&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;We begin to demonstrate the building blocks of a shinyApp.&lt;/p&gt;
&lt;p&gt;An App needs a &lt;em&gt;User interface (ui)&lt;/em&gt; and a server. The majic about the &lt;em&gt;shiny package&lt;/em&gt; is that it can create both of this within R, plus run your app using an additionational shiny function.&lt;/p&gt;
&lt;p&gt;First,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;load the library using the shiny.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(shiny)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create ui using the html function&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage()
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Define a custom function to create the server&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;server &amp;lt;- function(input,
                   output,
                   session){
  
                   }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;finally run your app.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example1-of-shiny-app&#34;&gt;Example1 of shiny app&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(shiny)
library(widgetframe)

ui &amp;lt;- fluidPage(
  &amp;quot;Hello, world!!!!!!&amp;quot;
)
  
server &amp;lt;- function(input,
                   output,
                   session){
  
                   }
  
  
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;example2-add-a-question&#34;&gt;Example2: Add a question&lt;/h3&gt;
&lt;p&gt;We want to go an extra mile an add a text that asks a question. This is possible but adding &lt;em&gt;textinput&lt;/em&gt; functuion that allows us to enter text. It has three arguments, a unique ID that will be used to refer to this input, a label that is displayed to the user and an optional default value.&lt;/p&gt;
&lt;p&gt;Our full out put that is diplayed is contained in the server using the render text function. Inside of that you can use &lt;em&gt;paste&lt;/em&gt; to create a longer character string. And if add &lt;em&gt;input$name&lt;/em&gt; you can access the name added using text input. The text is assigned to an output object that will be used in the ui to display.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(shiny)
library(widgetframe)

ui &amp;lt;- fluidPage(
  textInput(&amp;quot;name&amp;quot;, &amp;quot;Enter your name:&amp;quot;),
  textOutput(&amp;quot;r&amp;quot;)
)
  
server &amp;lt;- function(input, output){
  output$r &amp;lt;- renderText({
    paste0(&amp;quot;Do you prefer rain or sunshine,&amp;quot;, input$name, &amp;quot;?&amp;quot;)
  })
  
                   }
  
  
shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You did it a text that uses a text input!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Scale Shiny Dashboards</title>
      <link>https://victormandela.netlify.app/post/how-to-scale-shiny-dashboards/</link>
      <pubDate>Sun, 17 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/how-to-scale-shiny-dashboards/</guid>
      <description>&lt;p&gt;Most of the comments I get after sharing mock up and prototype shiny applications are:-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I love this app&lt;/li&gt;
&lt;li&gt;How fast did you add this features!!&lt;/li&gt;
&lt;li&gt;This is exactly what I need in my daily job at the company.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most of the people commenting, have never seen shiny applications before, know nothing about &lt;code&gt;R&lt;/code&gt; and they don&amp;rsquo;t really care that its running at the back of the application.&lt;/p&gt;
&lt;h2 id=&#34;challenges-faced-by-the-developer&#34;&gt;Challenges Faced by the developer.&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;The common problems I have faced are:-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Customizing user interface&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Increasing the user experience part&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scaling&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;scalable-applications&#34;&gt;Scalable Applications&lt;/h2&gt;
&lt;p&gt;Before we go into the remedies for this problems, I would first want us to understand the kinds of scaling there is:-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Vertical Scaling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;this is where we aim at ** increasing the amount of users for one machine**.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Horizontal scaling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scaling the application across multiple machines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;Scaling.jpg&#34; alt=&#34;Scaling&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;solutions-to-your-scaling-shiny-dashboards&#34;&gt;Solutions to your Scaling Shiny dashboards&lt;/h2&gt;
&lt;p&gt;Before we explain this are the main power points in brief:-&lt;/p&gt;
&lt;p&gt;a) Leveraging front end&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use Javascript to handle fast user interactions that do not change data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;b) Extract Computation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Handle resource intensive operations away from the application.&lt;/li&gt;
&lt;li&gt;Using external source to do the computation will assist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;c) Set Architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prepare applications to be used by many users.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The Main aim&lt;/strong&gt; is to make shiny layer thin. Shiny should be a thin layer between the data and the interface.&lt;/p&gt;
&lt;h2 id=&#34;using-the-power-of-the-browser&#34;&gt;Using the power of the browser&lt;/h2&gt;
&lt;p&gt;This is what you should do:-&lt;/p&gt;
&lt;p&gt;1). Render the input in &lt;code&gt;ui.R&lt;/code&gt; and only update them in &lt;code&gt;server.R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;2). Run inline Javascript code with &lt;code&gt;{Shinyjs}&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;3). Set all actions in Javascript without &lt;code&gt;server.R&lt;/code&gt; part.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(
  actionButton(
    &amp;quot;Click_Button&amp;quot;,
    label = &amp;quot;I will update icon!&amp;quot;,
    onclick = &amp;quot;$(&#39;mjs_update &amp;gt; i&#39;).toggle class(&#39;fa-arrow-up&#39;);&amp;quot;
    )
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extract-computation-remote-api&#34;&gt;Extract Computation: Remote API&lt;/h2&gt;
&lt;p&gt;Creating a API has been made achievable by use of the &lt;code&gt;plumber&lt;/code&gt; package.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Load only what is needed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The entire dataset is rarely needed in the application. Usually the first user action within the app is to filter/select a subset of data. First select them load.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build Rest API&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wrap data extraction login into a simple API with &lt;code&gt;{Plumber}&lt;/code&gt; by adding special comments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy Easily&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use Rstudio connect or Docker to host your API.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;extract-computation-using-database&#34;&gt;Extract computation: Using Database&lt;/h2&gt;
&lt;p&gt;Many may ask, **Why use Data base?&amp;quot;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ui &amp;lt;- fluidPage(....)

data &amp;lt;- readRDS(&amp;quot;./1gb-file.rds&amp;quot;)

Server &amp;lt;- function(input, output, session){
  
  output$search_result &amp;lt;- ... data %&amp;gt;% filter(value &amp;gt; input$query_value)
}

shinyApp(ui = ui, server = server)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because It reduces the amount of RAM used when you have many users. Its easy sinec you use the &lt;code&gt;dplyr&lt;/code&gt; package to manipulate the database.&lt;/p&gt;
&lt;h2 id=&#34;set-architecture&#34;&gt;Set Architecture&lt;/h2&gt;
&lt;p&gt;When deploying in the shiny server open source, you can use &lt;strong&gt;Ansible&lt;/strong&gt; to provision the infrastructure.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sentiment analysis</title>
      <link>https://victormandela.netlify.app/post/sentiment-analysis/</link>
      <pubDate>Sun, 17 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://victormandela.netlify.app/post/sentiment-analysis/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Data set&lt;/strong&gt;: &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-05-05/readme.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Animal Crossing user reviews from #TidyTuesday dataset&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Task&lt;/strong&gt;: Sentimental Analysis - Using the text from User reviews predict user ratings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expected results&lt;/strong&gt;: To check how positive or negative the user review is based on their comments.&lt;/p&gt;
&lt;h2 id=&#34;explore-the-data&#34;&gt;Explore the data&lt;/h2&gt;
&lt;p&gt;Let explore the data.&lt;/p&gt;
&lt;p&gt;We can see columns of the usernames, their reviews on how they feel the game was, the rating score grade, and the date they posted the review.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)

user_reviews &amp;lt;- readr::read_tsv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/user_reviews.tsv&#39;)

user_reviews %&amp;gt;%
  count(grade) %&amp;gt;%
  ggplot(aes(grade, n)) +
  geom_col(fill = &amp;quot;midnightblue&amp;quot;, alpha = 0.7)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://victormandela.netlify.app/post/2021-01-17-sentiment-analysis/index.en_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lots of people give scores of zero, and lots of people give scores of 10. This does not look like a nice distribution for predicting a not-even-really-continuous quantity like this &lt;code&gt;grade&lt;/code&gt;, so we&amp;rsquo;ll convert these user scores to a label, good vs. bad user reviews, and build a classification model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## not run here
user_reviews %&amp;gt;% 
  filter(grade &amp;gt; 8) %&amp;gt;% 
  sample_n(5) %&amp;gt;% 
  pull(text)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We definitely saw some evidence of scraping problems when looking at the review text. We will remove at least the final &lt;code&gt;&amp;quot;Expand&amp;quot;&lt;/code&gt; from the reviews, and create a new categorical &lt;code&gt;rating&lt;/code&gt; variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;reviews_parsed &amp;lt;- user_reviews %&amp;gt;%
  mutate(text = str_remove(text, &amp;quot;Expand$&amp;quot;)) %&amp;gt;%
  mutate(rating = case_when(grade &amp;gt; 7 ~ &amp;quot;good&amp;quot;,
                            TRUE ~ &amp;quot;bad&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the distribution of words per review?&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidytext)

words_per_review &amp;lt;- reviews_parsed %&amp;gt;%
  unnest_tokens(word, text) %&amp;gt;%
  count(user_name, name = &amp;quot;total_words&amp;quot;)

words_per_review %&amp;gt;%
  ggplot(aes(total_words)) +
  geom_histogram(fill = &amp;quot;midnightblue&amp;quot;, alpha = 0.8)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://victormandela.netlify.app/post/2021-01-17-sentiment-analysis/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t believe this can be a true, natural distribution of words per review. That sharp drop in the distribution looks very strange and I believe is a sign of some problem with the data generation process (i.e. a scraping problem). That&amp;rsquo;s life sometimes! Data is never perfect and sometimes we have to do the best we can with the data available. If this was my own project from start-to-finish, I would go back to the scraping and see if I could make any improvements at that stage.&lt;/p&gt;
&lt;p&gt;For now, let&amp;rsquo;s forge ahead and see what we can learn. There are lots more great examples of #TidyTuesday EDA out there to explore, &lt;a href=&#34;https://twitter.com/justynapawlata/status/1257718507002826752&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;including more text mining&lt;/a&gt;!&lt;/p&gt;
&lt;h2 id=&#34;build-a-model&#34;&gt;Build a model&lt;/h2&gt;
&lt;p&gt;We start by loading the tidymodels metapackage, that helps us in splitting our data into training and testing sets.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidymodels)

set.seed(123)
review_split &amp;lt;- initial_split(reviews_parsed, strata = rating)
review_train &amp;lt;- training(review_split)
review_test &amp;lt;- testing(review_split)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let&amp;rsquo;s &lt;strong&gt;preprocess&lt;/strong&gt; our data to get it ready for modeling. We can use specialized steps from &lt;a href=&#34;https://tidymodels.github.io/textrecipes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;textrecipes&lt;/a&gt;, along with the general recipe steps.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(textrecipes)
library(stopwords)

review_rec &amp;lt;- recipe(rating ~ text, data = review_train) %&amp;gt;%
  step_tokenize(text) %&amp;gt;%
  textrecipes::step_stopwords(text) %&amp;gt;%
  step_tokenfilter(text, max_tokens = 500) %&amp;gt;%
  step_tfidf(text) %&amp;gt;%
  step_normalize(all_predictors())

review_prep &amp;lt;- prep(review_rec)

review_prep
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          1
## 
## Training data contained 2250 data points and no missing data.
## 
## Operations:
## 
## Tokenization for text [trained]
## Stop word removal for text [trained]
## Text filtering for text [trained]
## Term frequency-inverse document frequency with text [trained]
## Centering and scaling for tfidf_text_0, tfidf_text_1, ... [trained]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s walk through the steps in this recipe, which are what I consider sensible defaults for a first attempt at training a text classification model such as a sentiment analysis model.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, we must tell the &lt;code&gt;recipe()&lt;/code&gt; what our model is going to be (using a formula here) and what data we are using.&lt;/li&gt;
&lt;li&gt;Next, we tokenize our text, with the default tokenization into single words.&lt;/li&gt;
&lt;li&gt;Next, we remove stop words (again, just the default set).&lt;/li&gt;
&lt;li&gt;It wouldn&amp;rsquo;t be practical to keep all the tokens from this whole dataset in our model, so we can filter down to only keep, in this case, the top 500 most-used tokens (after removing stop words). This is a pretty dramatic cut and keeping more tokens would be a good next step in improving this model.&lt;/li&gt;
&lt;li&gt;We need to decide on some kind of weighting for these tokens next, either something like term frequency or, what we used here, &lt;a href=&#34;https://www.tidytextmining.com/tfidf.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tf-idf&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Finally, we center and scale (i.e. normalize) all the newly created tf-idf values because the model we are going to use is sensitive to this.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before using &lt;code&gt;prep()&lt;/code&gt; these steps have been defined but not actually run or implemented. The &lt;code&gt;prep()&lt;/code&gt; function is where everything gets evaluated.&lt;/p&gt;
&lt;p&gt;Now it&amp;rsquo;s time to &lt;strong&gt;specify&lt;/strong&gt; our model. Here we can set up the model specification for lasso regression with &lt;code&gt;penalty = tune()&lt;/code&gt; since we don&amp;rsquo;t yet know the best value for the regularization parameter and &lt;code&gt;mixture = 1&lt;/code&gt; for lasso. In my experience, the lasso has proved to be a good baseline for text modeling. (And sometimes it is hard to do much better!)&lt;/p&gt;
&lt;p&gt;I am using a &lt;a href=&#34;https://tidymodels.github.io/workflows/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;workflow()&lt;/code&gt;&lt;/a&gt; in this example for convenience; these are objects that can help you manage modeling pipelines more easily, with pieces that fit together like Lego blocks. This &lt;code&gt;workflow()&lt;/code&gt; contains both the recipe and the model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lasso_spec &amp;lt;- logistic_reg(penalty = tune(), mixture = 1) %&amp;gt;%
  set_engine(&amp;quot;glmnet&amp;quot;)

lasso_wf &amp;lt;- workflow() %&amp;gt;%
  add_recipe(review_rec) %&amp;gt;%
  add_model(lasso_spec)

lasso_wf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## == Workflow ====================================================================
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## 5 Recipe Steps
## 
## * step_tokenize()
## * step_stopwords()
## * step_tokenfilter()
## * step_tfidf()
## * step_normalize()
## 
## -- Model -----------------------------------------------------------------------
## Logistic Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = tune()
##   mixture = 1
## 
## Computational engine: glmnet
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;tune-model-parameters&#34;&gt;Tune model parameters&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s get ready to &lt;a href=&#34;https://www.tidymodels.org/start/tuning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tune&lt;/a&gt; the lasso model! First, we need a set of possible regularization parameters to try.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lambda_grid &amp;lt;- grid_regular(penalty(), levels = 40)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we need a set of resampled data to fit and evaluate all these models.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(123)
review_folds &amp;lt;- bootstraps(review_train, strata = rating)
review_folds
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # Bootstrap sampling using stratification 
## # A tibble: 25 x 2
##    splits             id         
##    &amp;lt;list&amp;gt;             &amp;lt;chr&amp;gt;      
##  1 &amp;lt;split [2.2K/812]&amp;gt; Bootstrap01
##  2 &amp;lt;split [2.2K/850]&amp;gt; Bootstrap02
##  3 &amp;lt;split [2.2K/814]&amp;gt; Bootstrap03
##  4 &amp;lt;split [2.2K/814]&amp;gt; Bootstrap04
##  5 &amp;lt;split [2.2K/853]&amp;gt; Bootstrap05
##  6 &amp;lt;split [2.2K/840]&amp;gt; Bootstrap06
##  7 &amp;lt;split [2.2K/816]&amp;gt; Bootstrap07
##  8 &amp;lt;split [2.2K/826]&amp;gt; Bootstrap08
##  9 &amp;lt;split [2.2K/804]&amp;gt; Bootstrap09
## 10 &amp;lt;split [2.2K/809]&amp;gt; Bootstrap10
## # ... with 15 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can put it all together and implement the tuning. We can set specific metrics to compute during tuning with &lt;code&gt;metric_set()&lt;/code&gt;. Let&amp;rsquo;s look at AUC, positive predictive value, and negative predictive value so we can understand if one class is harder to predict than another.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;doParallel::registerDoParallel()

set.seed(2020)
lasso_grid &amp;lt;- tune_grid(
  lasso_wf,
  resamples = review_folds,
  grid = lambda_grid,
  metrics = metric_set(roc_auc, ppv, npv)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have our tuning results, we can examine them in detail.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lasso_grid %&amp;gt;%
  collect_metrics()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 x 7
##     penalty .metric .estimator  mean     n std_err .config              
##       &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                
##  1 1.00e-10 npv     binary     0.740    25 0.00518 Preprocessor1_Model01
##  2 1.00e-10 ppv     binary     0.864    25 0.00302 Preprocessor1_Model01
##  3 1.00e-10 roc_auc binary     0.878    25 0.00276 Preprocessor1_Model01
##  4 1.80e-10 npv     binary     0.740    25 0.00518 Preprocessor1_Model02
##  5 1.80e-10 ppv     binary     0.864    25 0.00302 Preprocessor1_Model02
##  6 1.80e-10 roc_auc binary     0.878    25 0.00276 Preprocessor1_Model02
##  7 3.26e-10 npv     binary     0.740    25 0.00518 Preprocessor1_Model03
##  8 3.26e-10 ppv     binary     0.864    25 0.00302 Preprocessor1_Model03
##  9 3.26e-10 roc_auc binary     0.878    25 0.00276 Preprocessor1_Model03
## 10 5.88e-10 npv     binary     0.740    25 0.00518 Preprocessor1_Model04
## # ... with 110 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Visualization is often more helpful to understand model performance.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lasso_grid %&amp;gt;%
  collect_metrics() %&amp;gt;%
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_line(size = 1.5, show.legend = FALSE) +
  facet_wrap(~.metric) +
  scale_x_log10()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://victormandela.netlify.app/post/2021-01-17-sentiment-analysis/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This shows us a lot. We see clearly that AUC and PPV have benefited from the regularization and we could identify the best value of &lt;code&gt;penalty&lt;/code&gt; for each of those metrics. The same is not true for NPV. One class (the happy comments) is harder to predict than the other. It might be worth including more tokens in our model, based on this plot.&lt;/p&gt;
&lt;h2 id=&#34;choose-the-final-model&#34;&gt;Choose the final model&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s keep our model as is for now, and choose a final model based on AUC. We can use &lt;code&gt;select_best()&lt;/code&gt; to find the best AUC and then update our workflow &lt;code&gt;lasso_wf&lt;/code&gt; with this value.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;best_auc &amp;lt;- lasso_grid %&amp;gt;%
  select_best(&amp;quot;roc_auc&amp;quot;)

best_auc
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   penalty .config              
##     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                
## 1 0.00889 Preprocessor1_Model32
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;final_lasso &amp;lt;- finalize_workflow(lasso_wf, best_auc)

final_lasso
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## == Workflow ====================================================================
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## -- Preprocessor ----------------------------------------------------------------
## 5 Recipe Steps
## 
## * step_tokenize()
## * step_stopwords()
## * step_tokenfilter()
## * step_tfidf()
## * step_normalize()
## 
## -- Model -----------------------------------------------------------------------
## Logistic Regression Model Specification (classification)
## 
## Main Arguments:
##   penalty = 0.00888623816274339
##   mixture = 1
## 
## Computational engine: glmnet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is our tuned, finalized workflow (but it is not fit yet). One of the things we can do when we start to fit this finalized workflow on the whole training set is to see what the most important variables are using the &lt;a href=&#34;https://koalaverse.github.io/vip/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vip&lt;/a&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(vip)

final_lasso %&amp;gt;%
  fit(review_train) %&amp;gt;%
  pull_workflow_fit() %&amp;gt;%
  vi(lambda = best_auc$penalty) %&amp;gt;%
  group_by(Sign) %&amp;gt;%
  top_n(20, wt = abs(Importance)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(Importance = abs(Importance),
         Variable = str_remove(Variable, &amp;quot;tfidf_text_&amp;quot;),
         Variable = fct_reorder(Variable, Importance)) %&amp;gt;%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~Sign, scales = &amp;quot;free_y&amp;quot;) +
  labs(y = NULL)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://victormandela.netlify.app/post/2021-01-17-sentiment-analysis/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;People who are happy with Animal Crossing like to talk about how relaxing, fantastic, enjoyable, and great it is, and also talk in their reviews about the &amp;ldquo;review bombing&amp;rdquo; of the negative reviews. Notice that many of the words from the negative reviews are specifically used to talk about the multiplayer experience (it&amp;rsquo;s boring for the second player, second player cannot do &amp;ldquo;anything&amp;rdquo; or move the story forward, cooperative/coop play doesn&amp;rsquo;t work well, etc). These users want a fix and they declare Nintendo greedy for the one-island-per-console play.&lt;/p&gt;
&lt;p&gt;Finally, let&amp;rsquo;s return to our test data. The tune package has a function &lt;code&gt;last_fit()&lt;/code&gt; which is nice for situations when you have tuned and finalized a model or workflow and want to fit it one last time on your training data and evaluate it on your testing data. You only have to pass this function your finalized model/workflow and your split.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;review_final &amp;lt;- last_fit(final_lasso, review_split)

review_final %&amp;gt;%
  collect_metrics()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 4
##   .metric  .estimator .estimate .config             
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;               
## 1 accuracy binary         0.892 Preprocessor1_Model1
## 2 roc_auc  binary         0.941 Preprocessor1_Model1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did not overfit during our tuning process, and the overall accuracy is not bad. Let&amp;rsquo;s create a confusion matrix for the testing data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;review_final %&amp;gt;%
  collect_predictions() %&amp;gt;%
  conf_mat(rating, .pred_class)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Truth
## Prediction bad good
##       bad  449   55
##       good  26  219
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although our overall accuracy isn&amp;rsquo;t so bad, we find that it is easier to detect the negative reviews than the positive ones.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
